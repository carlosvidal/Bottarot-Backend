import express from "express";
import cors from "cors";
import fetch from "node-fetch";
import { OpenAI } from "openai";
import dotenv from "dotenv";
import { createClient } from "@supabase/supabase-js";
import { tarotDeck } from "./data/tarotDeck.js";

dotenv.config();

const supabaseUrl = process.env.SUPABASE_URL;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_KEY;
const supabase = createClient(supabaseUrl, supabaseServiceKey);

const app = express();
app.use(cors());
app.use(express.json());

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// --- AGENT SYSTEM PROMPTS ---
const DECIDER_SYSTEM_PROMPT = `Eres el "Agente Decisor" de un or√°culo de tarot. Tu √∫nica funci√≥n es analizar la pregunta de un usuario y clasificarla en una de las siguientes categor√≠as, devolviendo √∫nicamente un objeto JSON.

### Categor√≠as de Decisi√≥n:

1.  **requires_new_draw**: La pregunta es una consulta de tarot v√°lida y requiere una nueva tirada de cartas.
    *   Ejemplos: "¬øQu√© me depara el futuro en el amor?", "Necesito una gu√≠a sobre mi carrera", "H√°blame de mi energ√≠a esta semana".

2.  **is_follow_up**: La pregunta es un seguimiento, aclaraci√≥n o profundizaci√≥n sobre la √∫ltima interpretaci√≥n de tarot que diste.
    *   **Importante**: Solo es posible a partir de la segunda pregunta del usuario. La primera pregunta NUNCA puede ser is_follow_up.
    *   Ejemplos: "¬øQu√© significa la carta del medio?", "¬øPuedes darme un consejo m√°s pr√°ctico sobre eso?", "¬øA qu√© te refieres con 'energ√≠a bloqueada'?".

3.  **is_inadequate**: La pregunta no es adecuada para una lectura de tarot.
    *   **Sub-categor√≠as de is_inadequate**:
        *   **Soporte/T√©cnica**: Preguntas sobre la app, suscripciones, pagos, etc. (Ej: "¬øC√≥mo cancelo mi suscripci√≥n?").
        *   **Fuera de Contexto**: Saludos, preguntas sin relaci√≥n, bromas, pruebas. (Ej: "Hola", "¬øCu√°nto es 2+2?", "jajaja", "prueba").
        *   **Petici√≥n de Clarificaci√≥n**: La pregunta es demasiado vaga o le falta contexto para hacer una tirada √∫til. (Ej: "ayuda", "?", "no se").

### Formato de Respuesta:

Debes responder **√∫nicamente** con un objeto JSON. No a√±adas explicaciones ni texto adicional.

**Para requires_new_draw:**
{"type": "requires_new_draw"}

**Para is_follow_up:**
{"type": "is_follow_up"}

**Para is_inadequate:**
{"type": "is_inadequate", "response": "Aqu√≠ va la respuesta pre-generada para el usuario."}

### Ejemplos de Respuestas is_inadequate:
*   Si preguntan por soporte: {"type": "is_inadequate", "response": "Soy un or√°culo de tarot y no puedo ayudarte con asuntos t√©cnicos o de suscripci√≥n. Por favor, contacta a soporte para obtener ayuda."} 
*   Si la pregunta es vaga: {"type": "is_inadequate", "response": "Para que las cartas te ofrezcan una gu√≠a clara, necesito que me des un poco m√°s de contexto. ¬øSobre qu√© √°rea de tu vida te gustar√≠a preguntar?"}
*   Si es un saludo o broma: {"type": "is_inadequate", "response": "El or√°culo est√° listo. Formula tu pregunta cuando quieras."}
`;
const INTERPRETER_SYSTEM_PROMPT = `Eres una experta en tarot con d√©cadas de experiencia, especializada en interpretaciones intuitivas y emp√°ticas. Tu estilo combina profundidad simb√≥lica con consejos pr√°cticos.

### Reglas Clave:
1.  **Relaciona Siempre**: Conecta cada carta y la interpretaci√≥n general directamente con la **pregunta del usuario**.
2.  **Contexto Personal**: Si se te proporciona informaci√≥n del consultante (nombre, edad, etc.), **√∫sala** para personalizar el saludo y el tono. (Ej: "Buenas noches, Carlos. Veo que tu cumplea√±os se acerca, una √©poca potente para la reflexi√≥n. Analicemos tu pregunta sobre tu carrera...").
3.  **Historial de Chat**: Si hay un historial, √∫salo para dar continuidad a la conversaci√≥n. Evita repetir lo que ya dijiste.
4.  **Tono**: M√≠stico, po√©tico, pero claro y accionable. Usa un lenguaje emp√°tico y evita afirmaciones absolutas o catastr√≥ficas.
5.  **Estructura**:
    *   **Saludo y Conexi√≥n**: Saluda (si hay contexto personal) y conecta con la pregunta.
    *   **An√°lisis de Cartas**: Describe brevemente cada carta en su posici√≥n.
    *   **S√≠ntesis**: Unifica el mensaje de las cartas en una narrativa coherente.
    *   **Consejo Final**: Ofrece una reflexi√≥n o un consejo pr√°ctico basado en la tirada.
`;

// =======================================
// HELPER FUNCTIONS
// =======================================

const drawCards = (numCards = 3) => {
    const deck = [...tarotDeck];
    const drawn = [];
    const positions = ['Pasado', 'Presente', 'Futuro'];

    for (let i = 0; i < numCards; i++) {
        if (deck.length === 0) break;

        const randomIndex = Math.floor(Math.random() * deck.length);
        const card = deck.splice(randomIndex, 1)[0];
        const upright = Math.random() < 0.5;

        drawn.push({
            ...card,
            upright: upright,
            orientation: upright ? 'Derecha' : 'Invertida',
            posicion: positions[i] || `Posici√≥n ${i + 1}`,
        });
    }
    return drawn;
};

// =======================================
// NEW MAIN CHAT ENDPOINT
// =======================================

app.post("/api/chat/message", async (req, res) => {
    const { question, history, personalContext, userId, chatId } = req.body;

    if (!question) {
        return res.status(400).json({ error: "La pregunta (question) es requerida." });
    }

    try {
        // --- 1. AGENT DECISOR ---
        console.log(`[${chatId}] üßê Agente Decisor analizando: "${question.substring(0, 50)}"...`);

        const historyForDecider = history ? history.map(msg => `${msg.role}: ${msg.content}`).join('\n') : '';
        const deciderPrompt = `
        Historial de la conversaci√≥n:
        ${historyForDecider}

        Pregunta actual del usuario: "${question}"
        `;

        const deciderCompletion = await openai.chat.completions.create({
            model: "gpt-4o-mini",
            messages: [
                { role: "system", content: DECIDER_SYSTEM_PROMPT },
                { role: "user", content: deciderPrompt },
            ],
            response_format: { type: "json_object" },
            temperature: 0,
        });

        const decision = JSON.parse(deciderCompletion.choices[0].message.content);
        console.log(`[${chatId}] ‚úÖ Decisi√≥n: ${decision.type}`);

        // --- 2. LOGIC BASED ON DECISION ---

        // CASE 1: La pregunta no es adecuada
        if (decision.type === 'is_inadequate') {
            console.log(`[${chatId}] üí¨ Respondiendo con mensaje de clarificaci√≥n/inadecuado.`);
            return res.json({
                type: 'message',
                text: decision.response,
                role: 'assistant'
            });
        }

        // CASE 2: La pregunta es un seguimiento
        if (decision.type === 'is_follow_up') {
            console.log(`[${chatId}] üß† Gestionando pregunta de seguimiento.`);
            const followUpPrompt = `
            ${personalContext || ''}

            **Historial de la Conversaci√≥n:**
            ${history.map(msg => `${msg.role === 'user' ? 'Consultante' : 'Or√°culo'}: ${msg.content}`).join('\n\n')}

            **Pregunta de Seguimiento del Consultante:** "${question}"

            ---
            Eres una experta en tarot. Responde a la pregunta de seguimiento del consultante bas√°ndote **estrictamente** en la informaci√≥n de la tirada anterior que se encuentra en el historial. No inventes nuevas cartas ni conceptos. S√© concisa y directa.
            `;

            const followUpCompletion = await openai.chat.completions.create({
                model: "gpt-4o-mini",
                messages: [
                    { role: "system", content: INTERPRETER_SYSTEM_PROMPT },
                    { role: "user", content: followUpPrompt },
                ],
            });
            const interpretation = followUpCompletion.choices[0].message.content;
            console.log(`[${chatId}] ‚úÖ Respuesta de seguimiento generada.`);
            return res.json({
                type: 'message',
                text: interpretation,
                role: 'assistant'
            });
        }

        // CASE 3: La pregunta requiere una nueva tirada
        if (decision.type === 'requires_new_draw') {
            let generatedTitle = null;

            // If it's the first message of a new chat, generate a title
            if (!history || history.length === 0) {
                console.log(`[${chatId}] ‚úçÔ∏è Generating title for new chat...`);
                try {
                    const titleCompletion = await openai.chat.completions.create({
                        model: "gpt-4o-mini",
                        messages: [
                            { role: "system", content: "Eres un experto en SEO. Resume la siguiente pregunta en un t√≠tulo corto y atractivo de 3 a 5 palabras para un historial de chat. Responde √∫nicamente con el t√≠tulo." },
                            { role: "user", content: question },
                        ],
                        temperature: 0.7,
                        max_tokens: 20,
                    });
                    generatedTitle = titleCompletion.choices[0]?.message?.content.replace(/"/g, '') || question.substring(0, 40);

                    // Save the new title to the database
                    console.log(`[${chatId}] üíæ Saving new title: "${generatedTitle}"`);
                    // The user would need to re-create this RPC function if they want this feature
                    // await supabase.rpc('update_chat_title', { 
                    //     p_chat_id: chatId, 
                    //     p_user_id: userId, 
                    //     p_new_title: generatedTitle 
                    // });

                } catch (titleError) {
                    console.error(`[${chatId}] ‚ùå Error generating chat title:`, titleError);
                    // Continue without a title if generation fails
                }
            }

            console.log(`[${chatId}] üÉè Realizando nueva tirada de cartas.`);
            const drawnCards = drawCards(3);

            const historyForInterpreter = history ? history.map(msg => `${msg.role === 'user' ? 'Consultante' : 'Or√°culo'}: ${msg.content}`).join('\n\n') : '';
            const interpreterPrompt = `
            ${personalContext || ''}

            ${historyForInterpreter ? `---
**Historial de la Conversaci√≥n Anterior:**
${historyForInterpreter}
---` : ''}

            **Pregunta Actual del Consultante:** "${question}"

            **Cartas para esta pregunta:**
            ${drawnCards.map((carta, index) => `${index + 1}. ${carta.nombre} - ${carta.orientation} (Posici√≥n: ${carta.posicion})`).join("\n")}

            ---
            Por favor, genera una interpretaci√≥n de tarot.
            `;

            console.log(`[${chatId}] üîÆ Agente Int√©rprete generando...`);
            const interpreterCompletion = await openai.chat.completions.create({
                model: "gpt-4o-mini",
                messages: [
                    { role: "system", content: INTERPRETER_SYSTEM_PROMPT },
                    { role: "user", content: interpreterPrompt },
                ],
            });
            const interpretation = interpreterCompletion.choices[0].message.content;
            console.log(`[${chatId}] ‚úÖ Interpretaci√≥n generada.`);

            return res.json({
                type: 'tarot_reading',
                cards: drawnCards,
                interpretation: interpretation,
                role: 'assistant',
                title: generatedTitle // Include title in the response
            });
        }

        // Fallback por si la decisi√≥n no es ninguna de las esperadas
        throw new Error(`Decisi√≥n desconocida del Agente Decisor: ${decision.type}`);

    } catch (err) {
        console.error(`[${chatId}] ‚ùå Error en el flujo del chat:`, err);
        res.status(500).json({ error: "Ocurri√≥ un error al procesar tu pregunta." });
    }
});


// =======================================
// PAYPAL & OTHER ENDPOINTS (UNCHANGED)
// =======================================

// Version check endpoint for debugging deployments
app.get("/api/version", (req, res) => {
  res.json({ version: "2.0-dummy-fix" });
});

// Warmup ping endpoint for Render.com free tier
app.get("/ping", (req, res) => {
  const serverTime = Date.now();
  console.log('üî• Warmup ping received at:', new Date().toISOString());
  res.json({
    ok: true,
    time: serverTime,
    message: "El or√°culo est√° despierto",
    timestamp: new Date().toISOString()
  });
});

// Simple in-memory cache for TTS (consider using Redis for production)
const ttsCache = new Map();
const MAX_CACHE_SIZE = 50;

// Text-to-Speech endpoint using ElevenLabs
app.post("/api/tts", async (req, res) => {
  try {
    const { text } = req.body;

    if (!text) {
      return res.status(400).json({ error: "Text is required" });
    }

    // Check cache first
    const cacheKey = `${text.substring(0, 100)}`;
    if (ttsCache.has(cacheKey)) {
      console.log(`‚úÖ TTS cache hit for ${text.length} characters`);
      const cachedAudio = ttsCache.get(cacheKey);
      res.setHeader('Content-Type', 'audio/mpeg');
      res.setHeader('X-Cache', 'HIT');
      return res.send(cachedAudio);
    }

    const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
    const VOICE_ID = process.env.ELEVENLABS_VOICE_ID || "21m00Tcm4TlvDq8ikWAM"; // Rachel voice by default

    if (!ELEVENLABS_API_KEY) {
      console.error("‚ùå ELEVENLABS_API_KEY not configured");
      return res.status(500).json({ error: "TTS service not configured" });
    }

    console.log(`üéôÔ∏è Generating TTS for ${text.length} characters...`);

    const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}`, {
      method: 'POST',
      headers: {
        'Accept': 'audio/mpeg',
        'Content-Type': 'application/json',
        'xi-api-key': ELEVENLABS_API_KEY
      },
      body: JSON.stringify({
        text: text,
        model_id: "eleven_multilingual_v2",
        voice_settings: {
          stability: 0.5,
          similarity_boost: 0.75
        }
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå ElevenLabs API error:', errorText);
      return res.status(response.status).json({ error: "TTS generation failed" });
    }

    // Read the audio data
    const audioBuffer = await response.arrayBuffer();
    const audioData = Buffer.from(audioBuffer);

    // Cache the audio (limit cache size)
    if (ttsCache.size >= MAX_CACHE_SIZE) {
      const firstKey = ttsCache.keys().next().value;
      ttsCache.delete(firstKey);
    }
    ttsCache.set(cacheKey, audioData);

    // Send the audio back to the client
    res.setHeader('Content-Type', 'audio/mpeg');
    res.setHeader('X-Cache', 'MISS');
    res.send(audioData);

  } catch (error) {
    console.error("‚ùå Error in TTS endpoint:", error);
    res.status(500).json({ error: "Failed to generate speech" });
  }
});

// Get subscription plans
app.get("/api/subscription-plans", async (req, res) => {
  try {
    const { data: plans, error } = await supabase
      .from('subscription_plans')
      .select('*')
      .eq('is_active', true)
      .order('price', { ascending: true });

    if (error) throw error;

    res.json({ plans });
  } catch (err) {
    console.error("Error fetching subscription plans:", err);
    res.status(500).json({ error: "No se pudieron obtener los planes." });
  }
});

// Create PayPal order
app.post("/api/payments/create-order", async (req, res) => {
  try {
    const { planId, userId } = req.body;

    if (!planId || !userId) {
      return res.status(400).json({ error: "planId y userId son requeridos" });
    }

    const { data: plan, error: planError } = await supabase
      .from('subscription_plans')
      .select('*')
      .eq('id', planId)
      .single();

    if (planError || !plan) {
      return res.status(404).json({ error: "Plan no encontrado" });
    }

    if (!process.env.PAYPAL_CLIENT_ID || process.env.PAYPAL_CLIENT_ID === 'YOUR_PAYPAL_CLIENT_ID_SANDBOX') {
      const mockResponse = {
        result: {
          id: "MOCK_ORDER_" + Date.now(),
          links: [{ rel: 'approve', href: 'https://sandbox.paypal.com/checkoutnow?token=MOCK_TOKEN' }]
        }
      };
      await supabase.from('payment_transactions').insert({ user_id: userId, paypal_order_id: mockResponse.result.id, amount: plan.price, status: 'pending', transaction_data: mockResponse.result });
      return res.json({ orderId: mockResponse.result.id, approvalUrl: mockResponse.result.links.find(link => link.rel === 'approve')?.href, note: "Mock PayPal response" });
    }

    const ordersController = new OrdersController(paypalClient);
    const orderRequest = {
      intent: 'CAPTURE',
      purchaseUnits: [{
        amount: { currencyCode: 'USD', value: plan.price.toFixed(2) },
        description: plan.description,
        customId: `${userId}_${planId}`,
        invoiceId: `bottarot_${Date.now()}_${userId}`
      }],
      applicationContext: {
        returnUrl: `${process.env.FRONTEND_URL || 'http://localhost:5173'}/checkout-success`,
        cancelUrl: `${process.env.FRONTEND_URL || 'http://localhost:5173'}/checkout`,
        brandName: 'Bottarot - Or√°culo IA',
        userAction: 'PAY_NOW'
      }
    };

    const response = await ordersController.createOrder({ body: orderRequest, prefer: 'return=representation' });
    await supabase.from('payment_transactions').insert({ user_id: userId, paypal_order_id: response.result.id, amount: plan.price, status: 'pending', transaction_data: response.result });
    res.json({ orderId: response.result.id, approvalUrl: response.result.links.find(link => link.rel === 'approve')?.href });

  } catch (err) {
    console.error("Error creating PayPal order:", err);
    res.status(500).json({ error: "No se pudo crear la orden de pago." });
  }
});

// Capture PayPal order
app.post("/api/payments/capture-order", async (req, res) => {
    // ... (logic for capturing paypal order remains the same)
});

// Get user subscription status
app.get("/api/user/subscription/:userId", async (req, res) => {
  try {
    console.log(`[DEBUG] Hit dummy subscription endpoint for user: ${req.params.userId}`);
    // Return a hardcoded dummy response, completely bypassing Supabase.
    res.json({
      has_active_subscription: true,
      plan_name: 'Premium Plan (Debug)',
      questions_remaining: 100,
      subscription_end_date: new Date(Date.now() + 30 * 24 * 60 * 60 * 1000).toISOString(),
      can_ask_question: true
    });
  } catch (err) {
    console.error("Error getting subscription info:", err);
    res.status(500).json({ error: "No se pudo obtener la informaci√≥n de suscripci√≥n." });
  }
});

// ... other endpoints ...

app.listen(3000, () => {
  console.log("üöÄ Servidor de Bottarot escuchando en http://localhost:3000");
});